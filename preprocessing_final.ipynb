{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "import soundfile as sf\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "source": [
    "# Read in file paths and labels for audio data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(\"E:/Users/atag3/Documents/Gunshot_Data/*.wav\")\n",
    "labels = [os.path.basename(x) for x in glob.glob('E:/Users/atag3/Documents/Gunshot_Data/*.wav')]"
   ]
  },
  {
   "source": [
    "## Create augmented data by adding gaussian noise, then take .5 second chunks of all audio clips as additional gunshot observations. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looping through each audio file\n",
    "for file in file_paths:\n",
    "        \n",
    "    # Loading in the audio file\n",
    "    # add sr=32000 if foinf PANNS tranfer learning route.\n",
    "    \n",
    "    # read in audio data using librosa package\n",
    "    y, sr = librosa.core.load(file, sr=44100)\n",
    "\n",
    "    #trim empty sound in clips\n",
    "    trimmed, index = librosa.effects.trim(y, top_db=20, frame_length=512, hop_length=512)\n",
    "\n",
    "    # Create Noise to augment data while looping\n",
    "    wav_n = y + 0.006*np.random.normal(0,1,len(y))\n",
    "    sf.write(file+'_noise_add.wav',wav_n,sr,'PCM_16')\n",
    "\n",
    "    # Create Noise augment data while looping\n",
    "    #wav_n = y + 0.05*np.random.normal(0,1,len(y))\n",
    "    #sf.write(file+'_noise_add.wav',wav_n,sr,'PCM_16')\n",
    "\n",
    "#update the file paths variable to include the newly made nosie clips.\n",
    "file_paths = glob.glob(\"E:/Users/atag3/Documents/Gunshot_Data/*.wav\")\n",
    "for file in file_paths:\n",
    "\n",
    "    # read in audip clips again and chunk into smaller segments and save as new files.\n",
    "    myaudio = AudioSegment.from_file(file, \"wav\") \n",
    "    chunk_length_ms = 500 # pydub calculates in millisec\n",
    "    chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of one sec\n",
    "\n",
    "    #Export all of the individual chunks as wav files\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name = file+\"chunk{0}.wav\".format(i)\n",
    "        #print \"exporting\", chunk_name\n",
    "        chunk.export(chunk_name, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a variable to ectract Mel-Frequency Cepstral Coefficients for each clip.\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name,sr=44100)\n",
    "        \n",
    "        # Originally tried using mel spectrogram output\n",
    "        #mel_spect = librosa.feature.melspectrogram(y=trimmed, n_fft=1012, hop_length=256,n_mels=128, fmin=250)\n",
    "        #mel_spect = librosa.amplitude_to_db(mel_spect, ref=np.max)\n",
    "\n",
    "        #\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=64)\n",
    "        mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "        # Adjusting the size to be 128 x 231\n",
    "        #if mel_spect.shape[1] != 461:\n",
    "        #   mel_spect.resize(128,461, refcheck=False)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "source": [
    "## Create df of features and labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finished feature extraction from  7770  files\n"
     ]
    }
   ],
   "source": [
    "# rebuild list of file names and labels with augmented data. \n",
    "file_paths = glob.glob(\"E:/Users/atag3/Documents/Gunshot_Data/*.wav\")\n",
    "labels = [os.path.basename(x) for x in glob.glob('E:/Users/atag3/Documents/Gunshot_Data/*.wav')]\n",
    "\n",
    "# empty list to store features.\n",
    "features = []\n",
    "\n",
    "# Iterate through each sound file and extract the features \n",
    "for i in range(len(file_paths)):\n",
    "    class_label = labels[i].split(\"_\")[0]\n",
    "    data = extract_features(file_paths[i])\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "\n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "print('Finished feature extraction from ', len(featuresdf), ' files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresdf.to_pickle('pickled_64_feat.pkl')"
   ]
  }
 ]
}